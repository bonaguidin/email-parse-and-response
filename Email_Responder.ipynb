{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bonaguidin/email-parse-and-response/blob/main/Email_Responder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Core Functions"
      ],
      "metadata": {
        "id": "ILBUdexr_S9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!pip install openai ipywidgets streamlit pyngrok fuzzywuzzy ipython gradio  # Explanation: Installing required packages\n",
        "\n",
        "# Clear output after installations\n",
        "from IPython.display import clear_output\n",
        "clear_output()  # Explanation: Clears the notebook output to keep the display clean\n",
        "\n",
        "# Imports\n",
        "import os\n",
        "import openai\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "import re\n",
        "import streamlit as st\n",
        "from pyngrok import ngrok\n",
        "from fuzzywuzzy import fuzz\n",
        "import gradio as gr\n",
        "from ipywidgets import Textarea, Dropdown\n",
        "\n",
        "print(\"‚úÖ All libraries successfully imported!\")  # Explanation: Confirmation message\n",
        "\n",
        "# Initialize SambaNova connection\n",
        "client = openai.OpenAI(\n",
        "    api_key=(\"REPLACE_WITH_API_KEY\"),  # Use SambaNova, OpenAI or API key of choice\n",
        "    base_url=\"https://api.sambanova.ai/v1\",\n",
        ")\n",
        "\n",
        "if client is not None:\n",
        "    print(\"‚úÖ Connection to SambaNova successful!\")\n",
        "else:\n",
        "    print(\"‚ùå Failed to connect to SambaNova.\")  # Explanation: Simple connection check message\n",
        "\n",
        "# AI Response Templates (Used for dynamic prompt instructions)\n",
        "PAST_TEMPLATES = {\n",
        "    \"tour_response\": \"Greet user, confirm tour interest, ask if they would like to schedule a tour or do so on a walk-in basis, and highlight the facilities.\",\n",
        "    \"membership_response\": \"Welcome the user, recommend programs, and mention the variety of options available. For questions, direct them to call 214-328-3849.\",\n",
        "}\n",
        "\n",
        "PROGRAM_DETAILS = {\n",
        "    \"Swim Programming\": \"Summer pool availability, swim lessons, pool rentals, swim team options.\",\n",
        "    \"Group Exercise Classes\": \"16+ classes, free with membership, social fitness benefits.\",\n",
        "    \"Youth Programming\": \"Seasonal sports (soccer, flag football, basketball, etc.).\",\n",
        "    \"Personal Training & Nutritional Coaching\": \"Individual, partner, and group training options.\",\n",
        "    \"Community\": \"Strong community for all ages and interests.\",\n",
        "    \"General Fitness\": \"Free weight area, gym equipment, and personal trainer session.\",\n",
        "}\n",
        "\n",
        "print(\"‚úÖ Templates and program details loaded!\")  # Explanation: Confirmation message for loaded templates\n",
        "\n",
        "# Core functionality\n",
        "def parse_structured_email(email_text):\n",
        "    \"\"\"Parses emails with more flexibility, extracting key information.\"\"\"\n",
        "\n",
        "    parsed = {}\n",
        "\n",
        "    # Extract Name\n",
        "    name_match = re.search(r\"(?:name|first and last name)\\s*:?\\s*([\\w\\s]+)\", email_text, re.IGNORECASE)\n",
        "    if name_match:\n",
        "        parsed['name'] = name_match.group(1).strip()\n",
        "    else:\n",
        "        # Fuzzy matching for name\n",
        "        lines = email_text.split('\\n')\n",
        "        best_match_score = 0\n",
        "        best_match_line = None\n",
        "        for line in lines:\n",
        "            score = fuzz.partial_ratio(\"name\", line.lower())\n",
        "            if score > best_match_score:\n",
        "                best_match_score = score\n",
        "                best_match_line = line\n",
        "        if best_match_score > 75:\n",
        "            name_value_match = re.search(r\"([\\w\\s]+)\", best_match_line, re.IGNORECASE)\n",
        "            if name_value_match:\n",
        "                parsed['name'] = name_value_match.group(1).strip()\n",
        "\n",
        "    # Extract Tour Request\n",
        "    tour_match = re.search(r\"(?:tour|schedule a tour)\\s*(yes|no|y|n)\", email_text, re.IGNORECASE)\n",
        "    if tour_match:\n",
        "        parsed['tour_request'] = tour_match.group(1).lower() in ('yes', 'y')\n",
        "    else:\n",
        "        # Fuzzy matching for tour request\n",
        "        lines = email_text.split('\\n')\n",
        "        best_match_score = 0\n",
        "        best_match_line = None\n",
        "        for line in lines:\n",
        "            score = fuzz.partial_ratio(\"tour\", line.lower())\n",
        "            if score > 75:\n",
        "                yes_no_match = re.search(r\"(yes|no|y|n)\", line.lower())\n",
        "                if yes_no_match:\n",
        "                    parsed['tour_request'] = yes_no_match.group(1).lower() in ('yes', 'y')\n",
        "\n",
        "    # Extract Interests\n",
        "    interests_match = re.search(r\"(?:interests?)\\s*:?\\s*(.+)\", email_text, re.IGNORECASE)\n",
        "    if interests_match:\n",
        "        parsed['interests'] = interests_match.group(1).strip()\n",
        "    else:\n",
        "        # Fuzzy matching for interests\n",
        "        lines = email_text.split('\\n')\n",
        "        best_match_score = 0\n",
        "        best_match_line = None\n",
        "        for line in lines:\n",
        "            score = fuzz.partial_ratio(\"interests\", line.lower())\n",
        "            if score > 75:\n",
        "                interests_value_match = re.search(r\"(.+)\", line, re.IGNORECASE)\n",
        "                if interests_value_match:\n",
        "                    parsed['interests'] = interests_value_match.group(1).strip()\n",
        "\n",
        "    print(\"Parsed data:\", parsed)\n",
        "    return parsed\n",
        "\n",
        "def generate_response(email_text, template_choice):\n",
        "    print(\"üí° Parsing email and generating response...\")  # Explanation: Debugging message\n",
        "\n",
        "    # Step 1: Extract User Information from Email\n",
        "    try:\n",
        "        parsed_data = parse_structured_email(email_text)\n",
        "        full_name = parsed_data.get('name', 'Member')\n",
        "        first_name = full_name.split()[0]  # Explanation: Use only the first name\n",
        "        user_interests = parsed_data.get('interests', '').lower()\n",
        "        wants_tour = parsed_data.get('tour_request', '').strip().lower() == 'yes'\n",
        "        tour_date = parsed_data.get('tour_date', None)  # Explanation: Assuming tour_date may exist in parsed data\n",
        "        phone_number = \"[Phone Number]\"  # Explanation: This should be updated or stored in a configuration\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error parsing email: {str(e)}\")\n",
        "        return f\"Error: Failed to parse email data. {str(e)}\"\n",
        "\n",
        "    # Step 2: Determine Relevant Programs Based on Interests\n",
        "    relevant_programs = [PROGRAM_DETAILS[prog] for prog in PROGRAM_DETAILS if any(word in user_interests for word in prog.lower().split())]\n",
        "    program_details_str = \"\\n\".join([f\"- {program}\" for program in relevant_programs])\n",
        "\n",
        "    # Step 3: Construct Dynamic AI Prompt for Email Response\n",
        "    try:\n",
        "        # Build a dynamic instruction prompt for the LLM\n",
        "        system_prompt = f\"\"\"You are a YMCA membership coordinator. Please craft a personalized email based on the following details:\n",
        "- First Name: {first_name}\n",
        "- Interests: {parsed_data.get('interests', 'Not provided')}\n",
        "- Tour Requested: {'Yes' if wants_tour else 'No'}\n",
        "- Relevant YMCA Programs: {program_details_str if program_details_str else 'General Fitness and Well-being'}\n",
        "\n",
        "Instructions: {PAST_TEMPLATES.get(template_choice.lower().replace(' ', '_'), 'Thank the user for submitting a web-form and provide necessary details.')}\n",
        "If a tour is requested, mention the that the user can call to schedule or simply drop in on a walk-in basis. Let the user know they can view this link for additional membership information: https://ymcadallas.org/join-y\n",
        "Use a warm, friendly tone.\n",
        "\"\"\"\n",
        "        print(\"‚úÖ Dynamic prompt constructed successfully!\")  # Explanation: Debug message\n",
        "\n",
        "        # Step 4: Generate email response using AI\n",
        "        response = client.chat.completions.create(\n",
        "            model='Meta-Llama-3.1-8B-Instruct',  # Explanation: Model selection for generating response\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},  # Explanation: System message with full instructions\n",
        "                {\"role\": \"user\", \"content\": \"Please generate the personalized email response.\"}  # Explanation: User message to trigger response generation\n",
        "            ],\n",
        "            temperature=0.9,  # Explanation: Controls creativity of the response\n",
        "            top_p=0.7,  # Explanation: Top-p sampling parameter\n",
        "            presence_penalty=0.3  # Explanation: Penalty to encourage new topics in generation\n",
        "        )\n",
        "        print(\"‚úÖ AI response generated successfully!\")\n",
        "        return response.choices[0].message.content\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error generating AI response: {str(e)}\")\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# Gradio interface\n",
        "def generate_response_gradio(email_text, template_choice):\n",
        "    return generate_response(email_text, template_choice)\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=generate_response_gradio,\n",
        "    inputs=[\n",
        "        gr.Textbox(lines=5, placeholder=\"Paste email here...\"),  # Explanation: Input field for the email text\n",
        "        gr.Dropdown(['Auto Select', 'Tour Response', 'Membership Response'], label=\"Template\"),  # Explanation: Dropdown for template selection\n",
        "    ],\n",
        "    outputs=gr.Textbox(lines=10, label=\"Generated Response\"),  # Explanation: Output field for the generated response\n",
        "    title=\"YMCA Email Responder\",\n",
        ")\n",
        "\n",
        "print(\"üöÄ Launching Gradio interface...\")  # Explanation: Notification before launching the interface\n",
        "interface.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "id": "OE8zQqC3ivaq",
        "outputId": "3e800c1e-a72d-4025-b26e-fece8358f835"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
            "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All libraries successfully imported!\n",
            "‚úÖ Connection to SambaNova successful!\n",
            "‚úÖ Templates and program details loaded!\n",
            "üöÄ Launching Gradio interface...\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://5285aa9742453ac81d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5285aa9742453ac81d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    }
  ]
}